# 单入口与中央大脑

> 内部端口繁杂，但**对用户只给一个简单明晰的入口**；用户需求由**中央大脑**解析并分发到对应处理端口，用户只关心需求，其余均为内部实现。  
> 本文档已按当前主仓**真实落地**的实现补充请求/响应契约、意图与分发逻辑及代码位置。

---

## 一、原则

| 对用户/助理侧 | 对主仓内部 |
|---------------|------------|
| **一个入口**：只需调用一个 API（`POST /v1/ask`），传入「用户说什么 / 想要什么」 | **多能力端口**：简历解析、职位匹配、诗人/诗词解析、征信解析、MBTI 等，以同仓模块形式存在（`agents`、`jobs`、`retrieval`） |
| **只关心需求**：不关心「该调哪个端口、哪个路径」 | **中央大脑**：`parse_intent(message)` → `dispatch(intent, request, slots)`，把请求转发到对应模块并聚合返回 |
| **统一响应**：无论背后走了哪条内部链路，对外均为 `AskResponse`（intent + result + suggestions） | **内部实现可替换**：端口与实现可随版本调整，对外契约不变 |

---

## 二、请求流（示意）

```
用户 / 助理
    │
    │  POST /v1/ask  { "message": "帮我匹配一下岗位", "resume_text": "..." }  或  { "message": "解析这段简历：张三，本科...", "context": {} }
    ▼
┌─────────────────────────────────────────────────────────┐
│  主仓 · 单入口 (Tatha API, tatha.api.app)                │
│  ┌───────────────────────────────────────────────────┐  │
│  │  中央大脑 (central_brain.handle_ask)                │  │
│  │  · parse_intent(message) → intent, confidence, slots  │
│  │  · dispatch(intent, request, slots) → result 字典   │  │
│  │  · 聚合为 AskResponse(intent, result, suggestions)   │  │
│  └───────────────────────────────────────────────────┘  │
│         │              │              │              │   │
│         ▼              ▼              ▼              ▼   │
│  [document_agents] [jobs.pipeline] [poetry RAG]  [credit]  │
│  简历/诗词/征信解析   run_job_match   get_query_engine   _document_analysis
└─────────────────────────────────────────────────────────┘
    │
    ▼
  统一 JSON  { "intent": "job_match", "result": { "message": "...", "matches": [...], "status": "ok", ... }, "suggestions": [] }
```

---

## 三、对外契约（当前实现）

### 3.1 入口与探活

- **单入口**：`POST /v1/ask`，请求体为 `AskRequest`（见下）；响应为 `AskResponse`。
- **探活**：`GET /health`，返回 `{"status": "ok", "service": "tatha"}`。
- **其他能力入口**（非意图路由，直接调用）：`POST /v1/documents/convert`（文档上传+提取）、`POST /v1/jobs/match`（职位匹配）、`POST /v1/rag/query`（RAG 查询）；助理可仅用 `/v1/ask`，也可按需调上述接口。

### 3.2 AskRequest / AskResponse

| 字段 | 类型 | 说明 |
|------|------|------|
| **message** | str | 必填。用户输入或意图描述（如「帮我匹配职位」「解析这段简历：…」）。 |
| **context** | dict | 可选。上下文（如 `user_id`、`session_id`、`resume_text`）。 |
| **resume_text** | str | 可选。用于 **job_match** 的简历全文；也可放在 `context.resume_text`。 |

响应 `AskResponse`：

| 字段 | 类型 | 说明 |
|------|------|------|
| **intent** | str | 解析出的意图：`job_match` / `resume_upload` / `poetry` / `credit` / `mbti` / `unknown`。 |
| **result** | dict | 能力端口返回的结果，通常含 `message`、`status`（ok / pending / error）、`slots`；部分意图含 `extracted`、`matches`、`total_evaluated`、`error`、`hint` 等。 |
| **suggestions** | list[str] | 可选后续建议（如 intent 为 unknown 时提示「可以说：帮我匹配职位、上传简历、推荐一句诗 等」）。 |

---

## 四、在 Tatha 中的落地

### 4.1 代码位置与流程

| 环节 | 位置 | 说明 |
|------|------|------|
| 单入口路由 | `tatha.api.app` | `POST /v1/ask` → `handle_ask(request)` |
| 意图解析 | `tatha.api.central_brain.parse_intent` | 主路径：LLM（LiteLLM）→ JSON 解析 → intent + confidence + slots；回退：`_parse_intent_rules` 关键词匹配 |
| 分发 | `tatha.api.central_brain.dispatch` | 按 intent 调用内部模块，返回 result 字典 |
| 统一响应 | `tatha.api.central_brain.handle_ask` | 将 result 与 confidence 填入 `AskResponse`，intent 为 unknown 时补 suggestions |

### 4.2 意图与分发逻辑（当前实现）

| intent | 触发条件（规则回退关键词） | 内部调用 | result 要点 |
|--------|---------------------------|----------|-------------|
| **job_match** | 匹配、职位、找工作、推荐、岗位 等 | 需 `resume_text` 或 `context.resume_text`；有则 `run_job_match_pipeline(resume_text)` | `status`: ok 时含 `matches`、`total_evaluated`；无简历时 `status`: pending，`hint` 提示上传或传入 resume_text |
| **resume_upload** | 上传、简历、解析简历 | 若 message 带正文：`_document_analysis("resume", text)`（PydanticAI/Marvin） | `status`: ok 时含 `extracted`（name、education、skills、experience_summary）；无正文时 pending |
| **poetry** | 诗词、诗人、古诗、推荐一句、陪伴、安慰 | 若 message 带正文：`_document_analysis("poetry", text)` | `status`: ok 时含 `extracted`（title、author、dynasty、content、theme）；无正文时 pending，hint 将接入 poetry RAG |
| **credit** | 征信、信用、验证 | **仅当** `_credit_has_document_body(text)` 为真（报告片段，非短句「查一下征信」）时调用 `_document_analysis("credit", text)` | `status`: ok 时含 `extracted`（entity_name、report_type、summary）；无正文或短句时 pending，hint 请提供报告摘要等 |
| **mbti** | 人格、MBTI、测评、性格 | 若 message 正文 ≥ 20 字：`MBTITextAnalyzer().analyze_text(text)` + `get_career_match(mbti_type)` | `status`: ok 时含 `extracted`（mbti_type、mbti_confidence、career_match 等）；无正文时 pending，hint 请描述做事风格或自述 |
| **unknown** | 未命中上述 | — | `status`: unknown，`received`: 消息前 100 字；suggestions 提示示例说法 |

### 4.3 征信「无正文」判断

业务流程上，征信为「匹配后查该公司」的后续步骤，主体来自匹配结果。若用户只说「查一下征信」而无报告内容，不应把整句当正文送 LLM 解析（易产生不稳定结果）。中央大脑通过 `_credit_has_document_body(text)` 判断：

- **视为有正文**：长度 ≥ 25 且含「主体」「报告类型」「摘要」「信用报告」等之一，或长度 ≥ 40 且含「信用/征信」。
- **视为无正文**：短句或仅查询语 → 直接返回 `status: pending`，`hint`: 请提供信用报告摘要或主体/报告类型/摘要等文本后再解析。

实现位置：`tatha.api.central_brain._credit_has_document_body`。

### 4.4 MBTI 轻量测评（无外仓、无 DB）

用户意图为 mbti 时，若消息正文不少于 20 字，中央大脑调用 `tatha.agents.mbti_analyzer.MBTITextAnalyzer` 做关键词维度分析（E/I、S/N、T/F、J/P），得到 mbti_type 后再用 `tatha.agents.mbti_career_match.get_career_match` 附加职业建议（适合职业、工作风格、优势与成长方向）。无正文或过短时返回 `status: pending`，hint 引导用户发一段自述。实现位置：`tatha.api.central_brain` 的 mbti 分支；分析器与职业表均在主仓内，无 MySQL/Neo4j 依赖。

### 4.5 文档解读与后端切换

`dispatch` 内对 resume / poetry / credit 的「带正文」分支统一走 `_document_analysis(document_type, text)`；mbti 单独走 `MBTITextAnalyzer` + `get_career_match`，见 4.4。

- **后端**：由 `TATHA_DOCUMENT_ANALYSIS_BACKEND` 控制，默认 `pydantic_ai`（类型安全 Agent）；失败或未配置时回退 `marvin`（由 `config/extractors_schema.example.json` 动态生成提取函数）。
- **返回**：可序列化 dict（如 `extracted`），供 `result` 返回给前端。

### 4.6 中央大脑与 LLM 进化（非占位）

- **主路径**：意图解析由 **LLM** 承担（LiteLLM），system prompt 约束输出 JSON（intent、confidence、slots）；改 prompt 或换模型即可迭代，无需为每种说法加规则。
- **回退**：未配置 API Key 或 LLM 调用失败时，用 `INTENT_KEYWORDS` 规则回退，保证单入口在任意环境下都能返回统一结构。
- **进化方式**：在保持「单入口 → parse_intent → dispatch → AskResponse」不变的前提下，可增加更细的 slot 抽取、多步推理等，均落在 LLM 的 prompt 或后续 agent 逻辑中。

详见 [设计说明_九库与Tatha.md](设计说明_九库与Tatha.md)；与收敛文档的对应见 [开发收敛与可交付路线图 §7.3](../JobFirst/docs/开发收敛与可交付路线图.md)。

---

## 五、内部微服务组织建议

内部「多能力端口」可以有两种形态：**同仓模块**（单进程内函数/模块调用）或 **真实微服务**（多进程/多端口，由中央大脑或网关转发）。建议先收敛、再按需拆分；若拆成微服务，**优先采用自主可控的 gozervi（Go）或 zervi-rust（rust-gozervi）** 做网关与认证层，AI 侧保留 Python（Tatha）；二者对 Python AI 同样友好，选型见 §5.4。

### 5.1 建议：先同仓模块，再按需拆微服务

**当前实现**：中央大脑（`central_brain.handle_ask`）与各能力均在同一进程内，`dispatch` 直接调用 `tatha.jobs.run_job_match_pipeline`、`_document_analysis` 等，无跨进程 HTTP。

| 阶段 | 做法 | 说明 |
|------|------|------|
| **V0 / 当前** | 内部能力以 **Tatha 主仓内模块** 存在（`core` / `ingest` / `agents` / `retrieval` / `jobs`） | 中央大脑在同一进程内通过函数调用分发，无跨进程；部署简单、排查方便，单入口与意图解析已跑通。 |
| **按需拆分** | 当某能力需独立扩缩容、独立部署或与现有 Go 服务复用时，再拆成**独立服务** | 解析、匹配、诗人 RAG 等 AI 密集仍建议 **Python**；认证、网关、转发等建议 **gozervi（Go）**，见下。 |

### 5.2 若拆微服务：推荐 gozervi / zervi-rust + Python 分工

| 层次 | 推荐技术 | 理由 |
|------|----------|------|
| **单入口网关 / 认证 / 转发** | **gozervi（Go）或 zervi-rust（Rust）** | 自主可控；JWT、OAuth2、RBAC、与现有 DB/Redis 对接；适合「对外唯一端口 + 鉴权 + 将 /v1/ask 转发到 Tatha」。二者对 Python 侧等价，选型见 §5.4。 |
| **中央大脑 + AI 能力** | **Tatha 主仓（Python）** | 意图解析、简历解析、匹配、诗人 RAG 等强依赖 LiteLLM、LlamaIndex、九库；保持 Python 可复用现有代码与生态。 |
| **征信 / MBTI / 人才验证** | **现有各仓（Go 或 Python）** | 可保留为独立服务，由中央大脑或网关通过 HTTP 调用；接口契约统一即可。 |

**两种常见拓扑**：

- **A）gozervi 或 zervi-rust 做网关，Tatha 做中央大脑**  
  用户请求 → **网关**（gozervi 或 zervi-rust：单入口、鉴权）→ 转发 `POST /v1/ask` 到 **Tatha 主仓**（Python）→ Tatha 内意图解析并调用内部模块或下游微服务 → 统一返回；征信/MBTI 等由 Tatha 或网关按配置转发。

- **B）Tatha 单进程同时做网关与中央大脑**  
  用户请求 → **Tatha 主仓**（Python，单端口）→ 内嵌鉴权（或调 gozervi/zervi-rust 校验 token）→ 意图解析与分发；适合 V0 或资源有限时，后续再在前侧加网关。

### 5.3 其他框架（备选）

| 方案 | 适用场景 |
|------|----------|
| **纯 Python 微服务** | 各能力均为 FastAPI 子应用，由同一 Python 网关或 Nginx 做路由；与 Tatha 同语言，易共享类型与工具，但认证与 Zervigo 对接需自建或复用 gozervi 的 HTTP 接口。 |
| **Kong / Nginx / Traefik** | 仅做反向代理与负载均衡时可用；鉴权与业务路由若希望自主可控，仍建议 gozervi 或 Tatha 内实现。 |
| **K8s / Docker Compose** | 部署与编排层；微服务本身仍建议按 5.2 选型（gozervi 网关 + Python 能力）。 |

**结论**：内部微服务组织优先 **自主可控的 gozervi 或 zervi-rust** 承担「单入口、认证、转发」；AI 与中央大脑留在 **Tatha（Python）**；先以同仓模块收敛，再按需拆成独立进程。选型对比见下 5.4。

### 5.4 gozervi（Go）与 zervi-rust（rust-gozervi）对比与选型

两者均为自主可控的 zervi 体系：**gozervi** 为 Go 版（与 Zervigo 同栈），**zervi-rust** 即 **rust-gozervi**（imartOS 下 Rust 版，JWT/OAuth2/RBAC、Tauri、可选 Axum/Actix-web HTTP 服务）。网关层二选一即可，对**后端 Python AI（Tatha）** 的友好程度一致。

#### 对 Python AI 开发的友好程度：**等价**

| 维度 | gozervi（Go） | zervi-rust（Rust） |
|------|----------------|---------------------|
| **与 Tatha 的边界** | HTTP：网关校验 token 后转发请求到 Tatha（Python），或透传 Header | 同上，HTTP 转发/透传 |
| **Python 侧感知** | 无差异：Tatha 只暴露 `POST /v1/ask` 等 REST，谁转发过来都一样 | 无差异 |
| **认证对接** | 网关校验 JWT，可把 `user_id` 等注入 Header 再转 Tatha；或 Tatha 调网关校验 | 同上，与 rust-gozervi 共享 DB/Redis，API 兼容 |
| **部署** | 网关与 Tatha 可同机或分机，仅需配置 Tatha 的 URL | 同上 |

**结论**：对 Python AI 开发而言，**两者谁更友好没有区别**——都是「前面多一层 HTTP 网关」，Tatha 只关心契约（请求/响应格式、Header 中的身份信息）。选型应主要看**栈统一、现有投入与运维**，见下。

#### 选型建议

| 倾向 | 更合适的方案 | 理由 |
|------|--------------|------|
| **前端/网关层统一用 Rust** | **zervi-rust（rust-gozervi）** | 助理侧已是 ZeroClaw（Rust）+ rust-gozervi；网关也用 Rust 则「单入口 + 认证 + 助理」全在 Rust，仅 Tatha 为 Python，语言栈更简单（Rust + Python 两套），且 Rust 单二进制、无运行时，适合树莓派/边缘。 |
| **与现有 Zervigo/生产 Go 体系一致** | **gozervi（Go）** | 若 Zervigo 与现网网关已是 Go，用 gozervi 可复用既有运维、监控与代码；Go 编译与迭代速度快，团队若更熟 Go 可优先。 |
| **希望网关与助理同进程/同二进制** | **zervi-rust** | rust-gozervi 可提供 HTTP 服务；若将来把「网关 + 本地助理」打成一个 Rust 二进制（如内嵌 ZeroClaw 或反向代理到 ZeroClaw），部署更简单。 |
| **暂时不引入网关** | **Tatha 单进程** | V0 可仍由 Tatha 直接对外，内嵌鉴权或调 gozervi/zervi-rust 的校验接口；待流量与安全需求上来再前挂网关。 |

**简要结论**：  
- **对 Python AI**：gozervi 与 zervi-rust **一样友好**，都是 HTTP 边界，Tatha 无需改代码。  
- **选型**：若希望**整体栈向 Rust 收敛**（助理 + 网关一体、边缘部署），优先 **zervi-rust**；若**强依赖现有 Go 与 Zervigo 生产**，优先 **gozervi**。两者也可并存（例如生产用 gozervi，本地/边缘用 zervi-rust 做代理），只要与 Tatha 的接口契约统一即可。
